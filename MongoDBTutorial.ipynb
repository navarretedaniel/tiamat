{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MongoDB with PyMongo and NOAA Data\n",
    "\n",
    "This notebook provides a basic walkthrough of how to use MongoDB and is based on a tutorial originally by [Alberto Negron](http://altons.github.io/python/2013/01/21/gentle-introduction-to-mongodb-using-pymongo/).\n",
    "\n",
    "## What is MongoDB?\n",
    "MongoDB is a cross-platform document-oriented NoSQL database. Rather than the traditional table-based relational database structure, MongoDB stores JSON-like documents with dynamic schemas (called BSON), making data integration easier and faster for certain types of applications.\n",
    "\n",
    "## Features\n",
    "Some of the features include:    \n",
    "\n",
    "__Document-orientation__\n",
    "Instead of taking a business subject and breaking it up into multiple relational structures, MongoDB can store the business subject in the minimal number of documents.    \n",
    "\n",
    "__Ad hoc queries__\n",
    "MongoDB supports field, range queries, regular expression searches. Queries can return specific fields of documents and also include user-defined JavaScript functions.    \n",
    "\n",
    "__Indexing__\n",
    "Any field in a MongoDB document can be indexed – including within arrays and embedded documents. Primary and secondary indices are available.    \n",
    "\n",
    "__Aggregation__\n",
    "Aggregation operators can be strung together to form a pipeline – analogous to Unix pipes.    \n",
    "\n",
    "\n",
    "## When it makes sense to use MongoDB    \n",
    "Metadata records are frequently stored as JSON, and almost anything you get from an API will be JSON. For example, check out the [metadata records](https://data.noaa.gov/data.json) for the National Oceanic and Atmospheric Administration. \n",
    "\n",
    "MongoDB is a great tool to use with JSON data because it stores structured data as JSON-like documents, using dynamic rather than predefined schemas. \n",
    "\n",
    "In MongoDB, an element of data is called a document, and documents are stored in collections. One collection may have any number of documents. Collections are a bit like tables in a relational database, and documents are like records. But there is one big difference: every record in a table has the same fields (with, usually, differing values) in the same order, while each document in a collection can have completely different fields from the other documents.\n",
    "\n",
    "Documents are Python dictionaries that can have strings as keys and can contain various primitive types (int, float,unicode, datetime) as well as other documents (Python dicts) and arrays (Python lists).\n",
    "\n",
    "## Getting started\n",
    "First we need to import `json` and `pymongo`.\n",
    "\n",
    "Note that the `pprint` module provides a capability to “pretty-print” arbitrary Python data structures in a form which can be used as input to the interpreter. This is particularly helpful with JSON. You can read more about `pprint` [here](https://docs.python.org/2/library/pprint.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pymongo\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect    \n",
    "Just as with the relational database example with `sqlite`, we need to begin by setting up a connection. With MongoDB, we will be using `pymongo`, though MongoDB also comes with a [console API that uses Javascript](https://docs.mongodb.org/manual/tutorial/write-scripts-for-the-mongo-shell/).    \n",
    "\n",
    "Make sure you have launched Mongo on your system before you connect.\n",
    "OS X - mongod\n",
    "Windows - net start MongoDB\n",
    "\n",
    "To make our connection, we will use the PyMongo method `MongoClient`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn=pymongo.MongoClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and access a database    \n",
    "\n",
    "Mongodb creates databases and collections automatically for you if they don't exist already. A single instance of MongoDB can support multiple independent databases. When working with PyMongo, we access databases using attribute style access, just like we did with `sqlite`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = conn.mydb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your connection fails, verify your Mongo server is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collections    \n",
    "A collection is a group of documents stored in MongoDB, and can be thought of as roughly the equivalent of a table in a relational database. Getting a collection in PyMongo works the same as getting a database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection = db.my_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data   \n",
    "To insert some data into MongoDB, all we need to do is create a dict and call `insert_one` on the collection object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = {\"class\":\"xbus-502\",\"date\":\"03-05-2016\",\"instructor\":\"bengfort\",\"classroom\":\"C222\",\"roster_count\":\"25\"}\n",
    "collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can put _anything_ in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = {\"class\":\"xbus-502\",\"date\":\"03-05-2016\",\"teaching_assistant\":\"bilbro\", \"sauce\": \"awesome\"}\n",
    "collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A practical example\n",
    "\n",
    "Rebecca Bilbro, former teaching assistant and current Visual Analytics instructor, has created this practical example for us to work through. \n",
    "\n",
    "At my job I have been working on a project to [help make Commerce datasets easier to find](https://github.com/CommerceDataService/recordtagger). One of the barriers to searching for records is when the keywords return either too many or too few results. It can also be a problem if the keywords are too technical for lay users. \n",
    "\n",
    "One solution is to use topic modeling to extract latent themes from the metadata records and then probabilistically assign each record a more sensical set of keywords based on its proximity (via kmeans) to the topics.\n",
    "\n",
    "In order to get started, first I had to gather up a bunch of JSON metadata records and store them for analysis and modeling. Here's what I did: \n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "NOAA_URL = \"https://data.noaa.gov/data.json\"\n",
    "\n",
    "def load_data(URL):\n",
    "    \"\"\"\n",
    "    Loads the data from URL and returns data in JSON format.\n",
    "    \"\"\"\n",
    "    r = requests.get(URL)\n",
    "    data = r.json()\n",
    "    return data\n",
    "    \n",
    "noaa = load_data(NOAA_URL)\n",
    "```\n",
    "\n",
    "But...this kinda takes a long time, so I've created a file for you that contains a small chunk of the records to use for today's workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data_sample.json\") as data_file:    \n",
    "    noaa = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(noaa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out the data\n",
    "Now let's print out just one record to examine the structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(noaa[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or say we wanted just the \"description\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(noaa[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the database\n",
    "We will want to enter these records into our database. But first, we'll define a specific database for the NOAA records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = conn.earthwindfire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the collection\n",
    "Next we define the collection where we'll insert the NOAA metadata records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = db.records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data    \n",
    "Then we loop through each record in the NOAA dataset and insert just the target information for each into the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What data fields seem important to you? Add them below following the examples:\n",
    "\n",
    "def insert(metadata):\n",
    "    for dataset in metadata:\n",
    "        data ={}\n",
    "        data[\"title\"] = dataset[\"title\"]\n",
    "        data[\"description\"] = dataset[\"description\"]\n",
    "        data[\"keywords\"] = dataset[\"keyword\"]\n",
    "        data[\"accessLevel\"] = dataset[\"accessLevel\"]\n",
    "        data[\"lang\"] = dataset[\"language\"]\n",
    "        # choose your own\n",
    "        # choose your own\n",
    "        # choose your own \n",
    "        # choose your own\n",
    "\n",
    "        records.insert_one(data)\n",
    "\n",
    "insert(noaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check to make sure they're all in there\n",
    "records.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying \n",
    "\n",
    "#### Querying with `.findOne( )`    \n",
    "The find_one() method selects and returns a single document from a collection and returns that document (or None if there are no matches). It is useful when you know there is only one matching document, or are only interested in the first match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying with `.find( )`\n",
    "To get more than a single document as the result of a query we use the `find()` method. `find()` returns a Cursor instance, which allows us to iterate over all matching documents.\n",
    "\n",
    "```python\n",
    "records.find()\n",
    "```\n",
    "\n",
    "For example, we can iterate over the first 2 documents (there are a lot in the collection and this is just an example) in the records collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rec in records.find()[:2]:\n",
    "    pprint(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching \n",
    "MongoDB queries are represented as JSON-like structures just like documents. To build a query, you just need to specify a dictionary with the properties you want the results to match. For example, let's say we were just interested in publically available satellite data from [NESDIS](http://www.nesdis.noaa.gov/).\n",
    "\n",
    "This query will match all documents in the records collection with keywords code \"NESDIS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records.find({\"keywords\": \"NESDIS\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1117 is probably more than we want to print out in a Jupyter Notebook...    \n",
    "\n",
    "We can further narrow our search by adding additional fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records.find({\"keywords\": \"NESDIS\",\"keywords\": \"Russia\",\"accessLevel\":\"public\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's only two, let's check them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r in records.find({\"keywords\": \"NESDIS\",\"keywords\": \"Russia\",\"accessLevel\":\"public\"}):\n",
    "    pprint(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you already know SQL...\n",
    "\n",
    "The following table provides an overview of common SQL aggregation terms, functions, and concepts and the corresponding MongoDB aggregation operators:    \n",
    "    \n",
    "| SQL Terms, Functions, and Concepts  | MongoDB Aggregation Operators  |\n",
    "| ----------------------------------  |:-------------------------------|\n",
    "| WHERE                               | \\$match                        |\n",
    "| GROUP BY                            | \\$group                        |\n",
    "| HAVING                              | \\$match                        |\n",
    "| SELECT\t                          | \\$project                      |\n",
    "| ORDER BY\t                          | \\$sort                         |\n",
    "| LIMIT                               | \\$limit                        |\n",
    "| SUM()   \t                          | \\$sum                          |\n",
    "| COUNT()\t                          | \\$sum                          |\n",
    "| join\t                              | \\$lookup                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But...thanks to MongoDB's nested data structures, we can also do a lot of things we can't do in a relational database. \n",
    "\n",
    "### Length    \n",
    "Let's look for some entries that have way too many keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.find({\"$where\": \"this.keywords.length > 100\"}).limit(2);\n",
    "for rec in cursor:\n",
    "    pprint(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full text search with a text index\n",
    "One of the things that makes MongoDB special is that it enables us to create search indexes. Indexes provide high performance read operations for frequently used queries.\n",
    "\n",
    "In particular, a __text index__ will enable us to search for string content in a collection. _Keep in mind that a collection can have at most one text index._ \n",
    "\n",
    "We will create a text index on the description field so that we can search inside our NOAA records text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.records.create_index([('description', 'text')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our newly created text index on the description field, we will search documents using the `$text` operator. Let's start by looking for all the documents that have the word 'precipitation' in their description field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.find({'$text': {'$search': 'precipitation'}})\n",
    "for rec in cursor:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.find({'$text': {'$search': 'fire'}})\n",
    "cursor.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to create a new text index, we can do so by first dropping the first text index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.records.drop_index(\"description_text\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a __wildcard__ text index for scenarios where we want any text fields in the records to be searchable. In such scenarios you can index all the string fields of your document using the $** wildcard specifier.\n",
    "\n",
    "The query would go something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.records.create_index([(\"$**\",\"text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.find({'$text': {'$search': \"Russia\"}})\n",
    "for rec in cursor:\n",
    "    pprint(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projections \n",
    "\n",
    "Projections allow you to pass along the documents with only the specified fields to the next stage in the pipeline. The specified fields can be existing fields from the input documents or newly computed fields.\n",
    "\n",
    "For example, let's redo our fulltext Russia search, but project just the titles of the records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.find({'$text': {'$search': \"Russia\"}}, {\"title\": 1,\"_id\":0 })\n",
    "for rec in cursor:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit    \n",
    "\n",
    "`.limit()` passes the first _n_ documents unmodified to the pipeline where _n_ is the specified limit. For each input document, this method outputs either one document (for the first _n_ documents) or zero documents (after the first _n_ documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.find({'$text': {'$search': \"Russia\"}}, {\"title\": 1,\"_id\":0 }).limit(2)\n",
    "for rec in cursor:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate\n",
    "MongoDB can perform aggregation operations with `.aggregate()`, such as grouping by a specified key and evaluating a total or a count for each distinct group.    \n",
    "\n",
    "Use the `$group` stage to group by a specified key using the \\_id field. `$group` accesses fields by the field path, which is the field name prefixed by a dollar sign.    \n",
    "\n",
    "For example, we can use `$group` to aggregate all the languages of the NOAA records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.aggregate(\n",
    "    [\n",
    "        {\"$group\": {\"_id\": \"$lang\", \"count\": {\"$sum\": 1}}}\n",
    "    ]\n",
    ")\n",
    "for document in cursor:\n",
    "    pprint(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can combine `$match` and `$group` to aggregate the titles of just the public access records that match the word 'Soviet':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.records.aggregate(\n",
    "    [\n",
    "        {\"$match\": {'$text': {'$search': \"Russia\"}, \"accessLevel\": \"public\"}},\n",
    "        {\"$group\": {\"_id\": \"$title\"}}\n",
    "    ]\n",
    ")\n",
    "\n",
    "for document in cursor:\n",
    "    pprint(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The aggregation pipeline \n",
    "\n",
    "The [aggregation pipeline](https://docs.mongodb.org/manual/core/aggregation-pipeline/) allows MongoDB to provide native aggregation capabilities that corresponds to many common data aggregation operations in SQL.  Here's where you will put the pieces together to aggregate to get results that you can begin to analyze and perform machine learning on.\n",
    "\n",
    "Here's an example of an aggregation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/mongodb_pipeline.png', width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing data    \n",
    "\n",
    "It's easy (almost too easy) to delete projects, collections, and databases in MongoDB. Before we get rid of anything, let's determine what collections we have in our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.earthwindfire.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete our records collection and check again to see what collections are in our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.earthwindfire.drop_collection(\"records\")\n",
    "conn.earthwindfire.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also just drop a database. First let's determine what databases we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's remove the earthwindfire database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.drop_database(\"earthwindfire\")\n",
    "conn.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous\n",
    "\n",
    "### Statistics    \n",
    "\n",
    "The [`dbstats`](https://docs.mongodb.org/manual/reference/method/db.stats/) method returns statistics that reflect the use state of a single database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = conn.mydb\n",
    "collection = db.my_collection\n",
    "db.command({'dbstats': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`collStats`](https://docs.mongodb.org/manual/reference/command/collStats/) returns a variety of storage statistics for a given collection. Let's try it out for our NOAA records collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.command({'collstats': 'my_collection', 'verbose': 'true' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
